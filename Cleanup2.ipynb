{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0144e82c",
   "metadata": {},
   "source": [
    "# Flight Data Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12cd74c",
   "metadata": {},
   "source": [
    "## Load source data into a single dataframe to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e749c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import zipfile\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cf2514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resources/BTS/BTS_Q1_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q2_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q3_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q4_2023.zip to Resources/BTS/extracted_zips\n"
     ]
    }
   ],
   "source": [
    "# List of all source zips\n",
    "zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "       'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "\n",
    "# Directory to extract to, confirm it exists\n",
    "extraction_path = 'Resources/BTS/extracted_zips'\n",
    "os.makedirs(extraction_path, exist_ok=True)\n",
    "\n",
    "# Iterate through zips and extract all\n",
    "for zip in zips:\n",
    "    with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extraction_path)\n",
    "\n",
    "    print(f\"Extracted {zip} to {extraction_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434d4838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Marketing_Airline_Network</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>DOT_ID_Marketing_Airline</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>...</th>\n",
       "      <th>Div5Airport</th>\n",
       "      <th>Div5AirportID</th>\n",
       "      <th>Div5AirportSeqID</th>\n",
       "      <th>Div5WheelsOn</th>\n",
       "      <th>Div5TotalGTime</th>\n",
       "      <th>Div5LongestGTime</th>\n",
       "      <th>Div5WheelsOff</th>\n",
       "      <th>Div5TailNum</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Unnamed: 119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "0  2023        1      1          22          7  2023-01-22   \n",
       "1  2023        1      1          22          7  2023-01-22   \n",
       "2  2023        1      1          22          7  2023-01-22   \n",
       "3  2023        1      1          22          7  2023-01-22   \n",
       "4  2023        1      1          22          7  2023-01-22   \n",
       "\n",
       "  Marketing_Airline_Network Operated_or_Branded_Code_Share_Partners  \\\n",
       "0                        B6                                      B6   \n",
       "1                        B6                                      B6   \n",
       "2                        B6                                      B6   \n",
       "3                        B6                                      B6   \n",
       "4                        B6                                      B6   \n",
       "\n",
       "   DOT_ID_Marketing_Airline IATA_Code_Marketing_Airline  ...  Div5Airport  \\\n",
       "0                     20409                          B6  ...          NaN   \n",
       "1                     20409                          B6  ...          NaN   \n",
       "2                     20409                          B6  ...          NaN   \n",
       "3                     20409                          B6  ...          NaN   \n",
       "4                     20409                          B6  ...          NaN   \n",
       "\n",
       "  Div5AirportID  Div5AirportSeqID Div5WheelsOn  Div5TotalGTime  \\\n",
       "0           NaN               NaN          NaN             NaN   \n",
       "1           NaN               NaN          NaN             NaN   \n",
       "2           NaN               NaN          NaN             NaN   \n",
       "3           NaN               NaN          NaN             NaN   \n",
       "4           NaN               NaN          NaN             NaN   \n",
       "\n",
       "  Div5LongestGTime  Div5WheelsOff Div5TailNum Duplicate  Unnamed: 119  \n",
       "0              NaN            NaN         NaN         N           NaN  \n",
       "1              NaN            NaN         NaN         N           NaN  \n",
       "2              NaN            NaN         NaN         N           NaN  \n",
       "3              NaN            NaN         NaN         N           NaN  \n",
       "4              NaN            NaN         NaN         N           NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all extracted CSV's\n",
    "# glob is an efficient way to work through all CSV's in a directory: https://docs.python.org/3/library/glob.html\n",
    "csv_files = glob.glob(f\"{extraction_path}/*.csv\")\n",
    "\n",
    "# Empty list for storing DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through csv's and store into DataFrames list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    dataframes.append(df)\n",
    "# Concatenante into single DataFrame\n",
    "unfiltered_flight_info = pd.concat(dataframes, ignore_index = True)\n",
    "unfiltered_flight_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6406ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>Operating_Airline</th>\n",
       "      <th>Flight_Number_Marketing_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1447</td>\n",
       "      <td>HPN</td>\n",
       "      <td>TPA</td>\n",
       "      <td>800</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1451</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MCO</td>\n",
       "      <td>1955</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1453</td>\n",
       "      <td>FLL</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1727</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1454</td>\n",
       "      <td>SJU</td>\n",
       "      <td>FLL</td>\n",
       "      <td>1140</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1455</td>\n",
       "      <td>BOS</td>\n",
       "      <td>DCA</td>\n",
       "      <td>700</td>\n",
       "      <td>652.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate IATA_Code_Marketing_Airline  \\\n",
       "0  2023-01-22                          B6   \n",
       "1  2023-01-22                          B6   \n",
       "2  2023-01-22                          B6   \n",
       "3  2023-01-22                          B6   \n",
       "4  2023-01-22                          B6   \n",
       "\n",
       "  Operated_or_Branded_Code_Share_Partners Operating_Airline   \\\n",
       "0                                      B6                 B6   \n",
       "1                                      B6                 B6   \n",
       "2                                      B6                 B6   \n",
       "3                                      B6                 B6   \n",
       "4                                      B6                 B6   \n",
       "\n",
       "   Flight_Number_Marketing_Airline Origin Dest  CRSDepTime  DepTime  DepDelay  \\\n",
       "0                             1447    HPN  TPA         800    756.0      -4.0   \n",
       "1                             1451    BOS  MCO        1955   2048.0      53.0   \n",
       "2                             1453    FLL  SJU        1727   1734.0       7.0   \n",
       "3                             1454    SJU  FLL        1140   1147.0       7.0   \n",
       "4                             1455    BOS  DCA         700    652.0      -8.0   \n",
       "\n",
       "   DepDelayMinutes  DepDel15  ArrDelay  ArrDelayMinutes  Cancelled  Diverted  \\\n",
       "0              0.0       0.0      -4.0              0.0        0.0       0.0   \n",
       "1             53.0       1.0      54.0             54.0        0.0       0.0   \n",
       "2              7.0       0.0      23.0             23.0        0.0       0.0   \n",
       "3              7.0       0.0       0.0              0.0        0.0       0.0   \n",
       "4              0.0       0.0     -17.0              0.0        0.0       0.0   \n",
       "\n",
       "   CarrierDelay  WeatherDelay  NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "0           NaN           NaN       NaN            NaN                NaN  \n",
       "1          39.0           0.0       1.0            0.0               14.0  \n",
       "2           7.0           0.0      16.0            0.0                0.0  \n",
       "3           NaN           NaN       NaN            NaN                NaN  \n",
       "4           NaN           NaN       NaN            NaN                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify columns and remove limitation on display\n",
    "pd.set_option('display.max_columns', None)\n",
    "flights_df = pd.DataFrame(unfiltered_flight_info[['FlightDate','IATA_Code_Marketing_Airline', \n",
    "                                                  'Operated_or_Branded_Code_Share_Partners',\n",
    "                                                  'Operating_Airline ','Flight_Number_Marketing_Airline',\n",
    "                                                  'Origin','Dest','CRSDepTime','DepTime',\n",
    "                                                  'DepDelay','DepDelayMinutes','DepDel15','ArrDelay',\n",
    "                                                  'ArrDelayMinutes','Cancelled','Diverted',\n",
    "                                                  'CarrierDelay','WeatherDelay','NASDelay',\n",
    "                                                  'SecurityDelay','LateAircraftDelay']])\n",
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c807325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Resources/BTS/extracted_zips and all its contents have been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Empty and delete the extraction_path directory\n",
    "try:\n",
    "    shutil.rmtree(extraction_path)\n",
    "    print(f\"Directory {extraction_path} and all its contents have been deleted.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e.strerror}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4309d3",
   "metadata": {},
   "source": [
    "## Explore and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e48bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique origin airports in data\n",
    "origins_df = unfiltered_flight_info[['Origin','OriginCityName']]\n",
    "origins_df['Origin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4b8747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique destination airports in data\n",
    "destinations_df = unfiltered_flight_info[['Dest','DestCityName']]\n",
    "destinations_df['Dest'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a016e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of unique airports in data\n",
    "# compare the origin airports to destination airports\n",
    "ori_match = origins_df['Origin'].isin(destinations_df['Dest'])\n",
    "dest_match = destinations_df['Dest'].isin(origins_df['Origin'])\n",
    "ori_dest_match = ori_match | dest_match\n",
    "\n",
    "# only keep rows for airports that are listed in both columns\n",
    "flight_airports = flights_df[ori_dest_match]\n",
    "flight_airports['Origin'].nunique()\n",
    "# confirmed that the same 359 airports have travel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb868ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV of cleaned us-airports and compare to airports in flight data\n",
    "us_airports = pd.read_csv('Resources/us-airports-cleaned.csv')\n",
    "iata_match = us_airports['iata_code'].isin(flight_airports['Origin'])\n",
    "\n",
    "us_airports_filtered = us_airports[iata_match]\n",
    "us_airports_filtered['iata_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bac33a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SJU', 'STT', 'BQN', 'PSE', 'STX', 'PPG', 'GUM', 'SPN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which 8 airports do we have data for that our airport list doesn't have?\n",
    "not_iata_match = flight_airports['Origin'].isin(us_airports_filtered['iata_code'])\n",
    "\n",
    "us_airports_missing = pd.DataFrame(flight_airports[~not_iata_match])\n",
    "us_airports_missing['Origin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66faa51e",
   "metadata": {},
   "source": [
    "Research (Google):\n",
    "SJU, BQM, PSE = Puerto Rico\n",
    "STT,STX, = U.S. Virgin Islands\n",
    "PPG = American Samoa (unincorporated territory)\n",
    "GUM = Guam\n",
    "SPN = Northern Mariana Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb306306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluding data from the 8 erroneous airports \n",
    "exclusions = flights_df['Origin'].isin(us_airports_missing['Origin'])\n",
    "\n",
    "filtered_flights = flights_df[~exclusions]\n",
    "filtered_flights['Origin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter airports to just those that have flight data\n",
    "us_airports = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aa3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44228a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Read in CSV and display a few rows\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# flight_csv = pd.read_csv('Resources/On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv', low_memory=False)\n",
    "# flight_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display columns without it being truncated because 'Operating_Airlines' column receives an error\n",
    "# print({col: index for index, col in enumerate(flight_csv.columns)})\n",
    "# # Discovered: 'Operating_Airline ' column has a space at the end in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20998dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select columns and create new dataframe \n",
    "# jan_flights_df = pd.DataFrame(flight_csv[['FlightDate','IATA_Code_Marketing_Airline', 'Operated_or_Branded_Code_Share_Partners',\n",
    "#                                       'Operating_Airline ','Flight_Number_Marketing_Airline','Tail_Number',\n",
    "#                                       'Origin','Dest','OriginCityName','DestCityName','CRSDepTime','DepTime',\n",
    "#                                       'DepDelay','DepDelayMinutes','DepDel15','ArrDelay','ArrDelayMinutes','Cancelled',\n",
    "#                                      'Diverted','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']])\n",
    "# jan_flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Airlines included\n",
    "# print(jan_flights_df['IATA_Code_Marketing_Airline'].value_counts())\n",
    "# print(jan_flights_df['Operating_Airline '].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e951be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #exporting to csv\n",
    "# jan_flights_df.to_csv('Resources/jan_flights_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4039f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the path to the ZIP file and the specific CSV file name inside the ZIP\n",
    "# source_zip = 'path/to/your/data.zip'\n",
    "# csv = 'your_file.csv'  # Name of the CSV file within the ZIP archive\n",
    "\n",
    "# # Use pandas.read_csv with the compression parameter\n",
    "# df = pd.read_csv(zip_file_path, compression='zip', encoding='utf-8', header=0, sep=',', quotechar='\"', error_bad_lines=False, engine='python', filepath_or_buffer=f\"zip://{zip_file_path}!{csv_file_name}\")\n",
    "\n",
    "# # Now you can work with the DataFrame `df` as usual\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c741e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Read in next CSV, select columns\n",
    "# column_selection = ['FlightDate','IATA_Code_Marketing_Airline', 'Operated_or_Branded_Code_Share_Partners',\n",
    "#                                       'Operating_Airline ','Flight_Number_Marketing_Airline','Tail_Number',\n",
    "#                                       'Origin','Dest','OriginCityName','DestCityName','CRSDepTime','DepTime',\n",
    "#                                       'DepDelay','DepDelayMinutes','DepDel15','ArrDelay','ArrDelayMinutes','Cancelled',\n",
    "#                                      'Diverted','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "# # more efficient way to work through multiple CSV's: https://docs.python.org/3/library/glob.html\n",
    "# csv_files = glob.glob('Resources/bts/*.csv')\n",
    "\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Iterate through each CSV file and append to list\n",
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(file, usecols=column_selection, low_memory = False)\n",
    "#     dataframes.append(df)\n",
    "\n",
    "# # Concatenate DataFrames from list to single df\n",
    "# combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "# combined_flight_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export to CSV\n",
    "# combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2121514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zip the CSV and delete to allow github upload\n",
    "# csv_path = 'Resources/combined_flight_info.csv'\n",
    "# zip_path = 'Resources/combined_flight_info.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#     zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "# # Confirm zip exists prior to deleting csv\n",
    "# if os.path.exists(zip_path):\n",
    "#     os.remove(csv_path)\n",
    "#     print(f\"The file {csv_file_path} has been zipped and deleted.\")\n",
    "# else:\n",
    "#     print(\"Error: The zip file was not created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de917093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import dependencies\n",
    "# import zipfile\n",
    "# import tempfile\n",
    "# import shutil\n",
    "# import glob\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in source CSVs, select columns, concat info\n",
    "\n",
    "# # List of all source zips\n",
    "# zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "#        'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "# # Prepare to select columns\n",
    "# column_selection = ['FlightDate','IATA_Code_Marketing_Airline','Operating_Airline ',\n",
    "#                     'Flight_Number_Marketing_Airline','Tail_Number','Origin','Dest',\n",
    "#                     'CRSDepTime','DepTime','DepDelay','DepDelayMinutes','DepDel15','ArrDelay',\n",
    "#                     'ArrDelayMinutes','Cancelled', 'Diverted','CarrierDelay',\n",
    "#                     'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Loop through zips and extract to a temp directory\n",
    "# for zip in zips:\n",
    "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#         with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(temp_dir)\n",
    "        \n",
    "#         # Use glob to find all CSV files in the temporary directory\n",
    "#         # https://docs.python.org/3/library/glob.html\n",
    "#         csv_files = glob.glob(os.path.join(temp_dir, '*.csv'))\n",
    "        \n",
    "#         # Iterate through CSV files\n",
    "#         for csv_file in csv_files:\n",
    "#             df = pd.read_csv(csv_file, usecols=column_selection, low_memory = False)\n",
    "#             dataframes.append(df)\n",
    "        \n",
    "#         # combine the dataframes\n",
    "#         combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "#         # export to new csv\n",
    "#         combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n",
    "# # Okay to close block and let temp_dir auto_delete\n",
    "# if os.path.exists('Resources/combined_flight_info.csv'):\n",
    "#     print(\"combined_flight_info.csv has been created\")\n",
    "# else: \n",
    "#     print(\"Something went wrong. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test it without selecting columns at first. \n",
    "# # Read in source CSVs, select columns, concat info\n",
    "\n",
    "# # List of all source zips\n",
    "# zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "#        'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Loop through zips and extract to a temp directory\n",
    "# for zip in zips:\n",
    "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#         with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(temp_dir)\n",
    "        \n",
    "#         # Use glob to find all CSV files in the temporary directory\n",
    "#         # https://docs.python.org/3/library/glob.html\n",
    "#         csv_files = glob.glob(os.path.join(temp_dir, '*.csv'))\n",
    "        \n",
    "#         # Iterate through CSV files\n",
    "#         for csv_file in csv_files:\n",
    "#             df = pd.read_csv(csv_file, low_memory = False)\n",
    "#             dataframes.append(df)\n",
    "        \n",
    "#         # combine the dataframes\n",
    "#         combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "#         # export to new csv\n",
    "#         combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n",
    "# # Okay to close block and let temp_dir auto_delete\n",
    "# if os.path.exists('Resources/combined_flight_info_unflitered.csv'):\n",
    "#     print(\"combined_flight_info_unfiltered.csv has been created\")\n",
    "# else: \n",
    "#     print(\"Something went wrong. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zip the CSV and delete to allow github upload\n",
    "# csv_path = 'Resources/combined_flight_info.csv'\n",
    "# zip_path = 'Resources/combined_flight_info.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#     zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "# # Confirm zip exists prior to deleting csv\n",
    "# if os.path.exists(zip_path):\n",
    "#     os.remove(csv_path)\n",
    "#     print(f\"The file {csv_path} has been zipped and deleted.\")\n",
    "# else:\n",
    "#     print(\"Error: Zip failed to create.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
