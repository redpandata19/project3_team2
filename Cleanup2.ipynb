{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0144e82c",
   "metadata": {},
   "source": [
    "# Pandas Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e749c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cf2514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resources/BTS/BTS_Q1_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q2_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q3_2023.zip to Resources/BTS/extracted_zips\n",
      "Extracted Resources/BTS/BTS_Q4_2023.zip to Resources/BTS/extracted_zips\n"
     ]
    }
   ],
   "source": [
    "# List of all source zips\n",
    "zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "       'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "\n",
    "# Directory to extract to, confirm it exists\n",
    "extraction_path = 'Resources/BTS/extracted_zips'\n",
    "os.makedirs(extraction_path, exist_ok=True)\n",
    "\n",
    "# Iterate through zips and extract all\n",
    "for zip in zips:\n",
    "    with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extraction_path)\n",
    "\n",
    "    print(f\"Extracted {zip} to {extraction_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434d4838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Marketing_Airline_Network</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>DOT_ID_Marketing_Airline</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>...</th>\n",
       "      <th>Div5Airport</th>\n",
       "      <th>Div5AirportID</th>\n",
       "      <th>Div5AirportSeqID</th>\n",
       "      <th>Div5WheelsOn</th>\n",
       "      <th>Div5TotalGTime</th>\n",
       "      <th>Div5LongestGTime</th>\n",
       "      <th>Div5WheelsOff</th>\n",
       "      <th>Div5TailNum</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Unnamed: 119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "0  2023        1      1          22          7  2023-01-22   \n",
       "1  2023        1      1          22          7  2023-01-22   \n",
       "2  2023        1      1          22          7  2023-01-22   \n",
       "3  2023        1      1          22          7  2023-01-22   \n",
       "4  2023        1      1          22          7  2023-01-22   \n",
       "\n",
       "  Marketing_Airline_Network Operated_or_Branded_Code_Share_Partners  \\\n",
       "0                        B6                                      B6   \n",
       "1                        B6                                      B6   \n",
       "2                        B6                                      B6   \n",
       "3                        B6                                      B6   \n",
       "4                        B6                                      B6   \n",
       "\n",
       "   DOT_ID_Marketing_Airline IATA_Code_Marketing_Airline  ...  Div5Airport  \\\n",
       "0                     20409                          B6  ...          NaN   \n",
       "1                     20409                          B6  ...          NaN   \n",
       "2                     20409                          B6  ...          NaN   \n",
       "3                     20409                          B6  ...          NaN   \n",
       "4                     20409                          B6  ...          NaN   \n",
       "\n",
       "  Div5AirportID  Div5AirportSeqID Div5WheelsOn  Div5TotalGTime  \\\n",
       "0           NaN               NaN          NaN             NaN   \n",
       "1           NaN               NaN          NaN             NaN   \n",
       "2           NaN               NaN          NaN             NaN   \n",
       "3           NaN               NaN          NaN             NaN   \n",
       "4           NaN               NaN          NaN             NaN   \n",
       "\n",
       "  Div5LongestGTime  Div5WheelsOff Div5TailNum Duplicate  Unnamed: 119  \n",
       "0              NaN            NaN         NaN         N           NaN  \n",
       "1              NaN            NaN         NaN         N           NaN  \n",
       "2              NaN            NaN         NaN         N           NaN  \n",
       "3              NaN            NaN         NaN         N           NaN  \n",
       "4              NaN            NaN         NaN         N           NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all CSV's extracted into extraction_path\n",
    "# glob is an efficient way to work through multiple CSV's: https://docs.python.org/3/library/glob.html\n",
    "csv_files = glob.glob(f\"{extraction_path}/*.csv\")\n",
    "\n",
    "# Empty list for storing DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through csv's and store into DataFrames list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    dataframes.append(df)\n",
    "# Concatenante into single DataFrame\n",
    "unfiltered_flight_info = pd.concat(dataframes, ignore_index = True)\n",
    "unfiltered_flight_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6406ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>Operating_Airline</th>\n",
       "      <th>Flight_Number_Marketing_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1447</td>\n",
       "      <td>N636JB</td>\n",
       "      <td>HPN</td>\n",
       "      <td>TPA</td>\n",
       "      <td>800</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1451</td>\n",
       "      <td>N3112J</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MCO</td>\n",
       "      <td>1955</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1453</td>\n",
       "      <td>N507JT</td>\n",
       "      <td>FLL</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1727</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1454</td>\n",
       "      <td>N956JT</td>\n",
       "      <td>SJU</td>\n",
       "      <td>FLL</td>\n",
       "      <td>1140</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>1455</td>\n",
       "      <td>N249JB</td>\n",
       "      <td>BOS</td>\n",
       "      <td>DCA</td>\n",
       "      <td>700</td>\n",
       "      <td>652.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate IATA_Code_Marketing_Airline  \\\n",
       "0  2023-01-22                          B6   \n",
       "1  2023-01-22                          B6   \n",
       "2  2023-01-22                          B6   \n",
       "3  2023-01-22                          B6   \n",
       "4  2023-01-22                          B6   \n",
       "\n",
       "  Operated_or_Branded_Code_Share_Partners Operating_Airline   \\\n",
       "0                                      B6                 B6   \n",
       "1                                      B6                 B6   \n",
       "2                                      B6                 B6   \n",
       "3                                      B6                 B6   \n",
       "4                                      B6                 B6   \n",
       "\n",
       "   Flight_Number_Marketing_Airline Tail_Number Origin Dest  CRSDepTime  \\\n",
       "0                             1447      N636JB    HPN  TPA         800   \n",
       "1                             1451      N3112J    BOS  MCO        1955   \n",
       "2                             1453      N507JT    FLL  SJU        1727   \n",
       "3                             1454      N956JT    SJU  FLL        1140   \n",
       "4                             1455      N249JB    BOS  DCA         700   \n",
       "\n",
       "   DepTime  DepDelay  DepDelayMinutes  DepDel15  ArrDelay  ArrDelayMinutes  \\\n",
       "0    756.0      -4.0              0.0       0.0      -4.0              0.0   \n",
       "1   2048.0      53.0             53.0       1.0      54.0             54.0   \n",
       "2   1734.0       7.0              7.0       0.0      23.0             23.0   \n",
       "3   1147.0       7.0              7.0       0.0       0.0              0.0   \n",
       "4    652.0      -8.0              0.0       0.0     -17.0              0.0   \n",
       "\n",
       "   Cancelled  Diverted  CarrierDelay  WeatherDelay  NASDelay  SecurityDelay  \\\n",
       "0        0.0       0.0           NaN           NaN       NaN            NaN   \n",
       "1        0.0       0.0          39.0           0.0       1.0            0.0   \n",
       "2        0.0       0.0           7.0           0.0      16.0            0.0   \n",
       "3        0.0       0.0           NaN           NaN       NaN            NaN   \n",
       "4        0.0       0.0           NaN           NaN       NaN            NaN   \n",
       "\n",
       "   LateAircraftDelay  \n",
       "0                NaN  \n",
       "1               14.0  \n",
       "2                0.0  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify columns and remove limitation on display\n",
    "pd.set_option('display.max_columns', None)\n",
    "flights_df = pd.DataFrame(unfiltered_flight_info[['FlightDate','IATA_Code_Marketing_Airline', \n",
    "                                                  'Operated_or_Branded_Code_Share_Partners',\n",
    "                                                  'Operating_Airline ','Flight_Number_Marketing_Airline',\n",
    "                                                  ,'Origin','Dest','CRSDepTime','DepTime',\n",
    "                                                  'DepDelay','DepDelayMinutes','DepDel15','ArrDelay',\n",
    "                                                  'ArrDelayMinutes','Cancelled','Diverted',\n",
    "                                                  'CarrierDelay','WeatherDelay','NASDelay',\n",
    "                                                  'SecurityDelay','LateAircraftDelay']])\n",
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84e48bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origins_df = unfiltered_flight_info[['Origin','OriginCityName']]\n",
    "origins_df['Origin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c4b8747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_df = unfiltered_flight_info[['Dest','DestCityName']]\n",
    "destinations_df['Dest'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c807325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THE EXTRACTION PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44228a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Read in CSV and display a few rows\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# flight_csv = pd.read_csv('Resources/On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv', low_memory=False)\n",
    "# flight_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display columns without it being truncated because 'Operating_Airlines' column receives an error\n",
    "# print({col: index for index, col in enumerate(flight_csv.columns)})\n",
    "# # Discovered: 'Operating_Airline ' column has a space at the end in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20998dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select columns and create new dataframe \n",
    "# jan_flights_df = pd.DataFrame(flight_csv[['FlightDate','IATA_Code_Marketing_Airline', 'Operated_or_Branded_Code_Share_Partners',\n",
    "#                                       'Operating_Airline ','Flight_Number_Marketing_Airline','Tail_Number',\n",
    "#                                       'Origin','Dest','OriginCityName','DestCityName','CRSDepTime','DepTime',\n",
    "#                                       'DepDelay','DepDelayMinutes','DepDel15','ArrDelay','ArrDelayMinutes','Cancelled',\n",
    "#                                      'Diverted','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']])\n",
    "# jan_flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Airlines included\n",
    "# print(jan_flights_df['IATA_Code_Marketing_Airline'].value_counts())\n",
    "# print(jan_flights_df['Operating_Airline '].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e951be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #exporting to csv\n",
    "# jan_flights_df.to_csv('Resources/jan_flights_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4039f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the path to the ZIP file and the specific CSV file name inside the ZIP\n",
    "# source_zip = 'path/to/your/data.zip'\n",
    "# csv = 'your_file.csv'  # Name of the CSV file within the ZIP archive\n",
    "\n",
    "# # Use pandas.read_csv with the compression parameter\n",
    "# df = pd.read_csv(zip_file_path, compression='zip', encoding='utf-8', header=0, sep=',', quotechar='\"', error_bad_lines=False, engine='python', filepath_or_buffer=f\"zip://{zip_file_path}!{csv_file_name}\")\n",
    "\n",
    "# # Now you can work with the DataFrame `df` as usual\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c741e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Read in next CSV, select columns\n",
    "# column_selection = ['FlightDate','IATA_Code_Marketing_Airline', 'Operated_or_Branded_Code_Share_Partners',\n",
    "#                                       'Operating_Airline ','Flight_Number_Marketing_Airline','Tail_Number',\n",
    "#                                       'Origin','Dest','OriginCityName','DestCityName','CRSDepTime','DepTime',\n",
    "#                                       'DepDelay','DepDelayMinutes','DepDel15','ArrDelay','ArrDelayMinutes','Cancelled',\n",
    "#                                      'Diverted','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "# # more efficient way to work through multiple CSV's: https://docs.python.org/3/library/glob.html\n",
    "# csv_files = glob.glob('Resources/bts/*.csv')\n",
    "\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Iterate through each CSV file and append to list\n",
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(file, usecols=column_selection, low_memory = False)\n",
    "#     dataframes.append(df)\n",
    "\n",
    "# # Concatenate DataFrames from list to single df\n",
    "# combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "# combined_flight_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export to CSV\n",
    "# combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2121514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zip the CSV and delete to allow github upload\n",
    "# csv_path = 'Resources/combined_flight_info.csv'\n",
    "# zip_path = 'Resources/combined_flight_info.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#     zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "# # Confirm zip exists prior to deleting csv\n",
    "# if os.path.exists(zip_path):\n",
    "#     os.remove(csv_path)\n",
    "#     print(f\"The file {csv_file_path} has been zipped and deleted.\")\n",
    "# else:\n",
    "#     print(\"Error: The zip file was not created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de917093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import dependencies\n",
    "# import zipfile\n",
    "# import tempfile\n",
    "# import shutil\n",
    "# import glob\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in source CSVs, select columns, concat info\n",
    "\n",
    "# # List of all source zips\n",
    "# zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "#        'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "# # Prepare to select columns\n",
    "# column_selection = ['FlightDate','IATA_Code_Marketing_Airline','Operating_Airline ',\n",
    "#                     'Flight_Number_Marketing_Airline','Tail_Number','Origin','Dest',\n",
    "#                     'CRSDepTime','DepTime','DepDelay','DepDelayMinutes','DepDel15','ArrDelay',\n",
    "#                     'ArrDelayMinutes','Cancelled', 'Diverted','CarrierDelay',\n",
    "#                     'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Loop through zips and extract to a temp directory\n",
    "# for zip in zips:\n",
    "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#         with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(temp_dir)\n",
    "        \n",
    "#         # Use glob to find all CSV files in the temporary directory\n",
    "#         # https://docs.python.org/3/library/glob.html\n",
    "#         csv_files = glob.glob(os.path.join(temp_dir, '*.csv'))\n",
    "        \n",
    "#         # Iterate through CSV files\n",
    "#         for csv_file in csv_files:\n",
    "#             df = pd.read_csv(csv_file, usecols=column_selection, low_memory = False)\n",
    "#             dataframes.append(df)\n",
    "        \n",
    "#         # combine the dataframes\n",
    "#         combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "#         # export to new csv\n",
    "#         combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n",
    "# # Okay to close block and let temp_dir auto_delete\n",
    "# if os.path.exists('Resources/combined_flight_info.csv'):\n",
    "#     print(\"combined_flight_info.csv has been created\")\n",
    "# else: \n",
    "#     print(\"Something went wrong. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test it without selecting columns at first. \n",
    "# # Read in source CSVs, select columns, concat info\n",
    "\n",
    "# # List of all source zips\n",
    "# zips = ['Resources/BTS/BTS_Q1_2023.zip','Resources/BTS/BTS_Q2_2023.zip',\n",
    "#        'Resources/BTS/BTS_Q3_2023.zip','Resources/BTS/BTS_Q4_2023.zip']\n",
    "# # Empty list for DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Loop through zips and extract to a temp directory\n",
    "# for zip in zips:\n",
    "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#         with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(temp_dir)\n",
    "        \n",
    "#         # Use glob to find all CSV files in the temporary directory\n",
    "#         # https://docs.python.org/3/library/glob.html\n",
    "#         csv_files = glob.glob(os.path.join(temp_dir, '*.csv'))\n",
    "        \n",
    "#         # Iterate through CSV files\n",
    "#         for csv_file in csv_files:\n",
    "#             df = pd.read_csv(csv_file, low_memory = False)\n",
    "#             dataframes.append(df)\n",
    "        \n",
    "#         # combine the dataframes\n",
    "#         combined_flight_info = pd.concat(dataframes, ignore_index=True)\n",
    "#         # export to new csv\n",
    "#         combined_flight_info.to_csv('Resources/combined_flight_info.csv')\n",
    "# # Okay to close block and let temp_dir auto_delete\n",
    "# if os.path.exists('Resources/combined_flight_info_unflitered.csv'):\n",
    "#     print(\"combined_flight_info_unfiltered.csv has been created\")\n",
    "# else: \n",
    "#     print(\"Something went wrong. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zip the CSV and delete to allow github upload\n",
    "# csv_path = 'Resources/combined_flight_info.csv'\n",
    "# zip_path = 'Resources/combined_flight_info.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#     zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "# # Confirm zip exists prior to deleting csv\n",
    "# if os.path.exists(zip_path):\n",
    "#     os.remove(csv_path)\n",
    "#     print(f\"The file {csv_path} has been zipped and deleted.\")\n",
    "# else:\n",
    "#     print(\"Error: Zip failed to create.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
